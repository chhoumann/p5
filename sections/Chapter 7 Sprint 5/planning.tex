\section{Sprint Planning}
In this sprint, we will be working on the RDF database seeing as the WordCount database is now finished.
We will focus on creating user stories from epics, and these epics will then be granulated into tasks. 
Here epics are seen as a larger body of work that can then be granulated into user stories \cite{Epics}.
This will ultimately result in the backlog for this sprint.

\subsection*{User stories}\label{sec:userstories5}
The \knox{} product owner have given us three user stories, which we can use to detail the coming tasks for the sprint.
Our own product owner, along with the second and fourth layer, granulated these user stories as we consider them to be \textit{epics}.
This helped us understand how to accommodate the needs of the two layers and prioritize the stories.
This in turn helped us generate as much value to the pipeline, as quickly as possible \cite{UserStories}.

\userStory{the knowledge layer}{to be able to insert Triples into a storage}{can access it later}
\userStory{the functionality layer}{to be able to query an RDF graph}{can use it in search results, fact checking and virtual assistant applications}
\userStory{the functionality layer}{to be able to query an RDF graph in a standardized way}{do not have to worry about changes to the database}

\subsubsection*{Granulating the epics}
After talking to the functionality and knowledge layer, we found out some of the details about how they want database access to work. These requirements are specified below.

\begin{enumerate}
    \item They want it to be possible to write RDF data to the Fuseki database using the Terse RDF Triple Language (Turtle) syntax and file format \cite{TurtleFormat}.
    \item They want to be able to send SPARQL queries directly to an endpoint to fetch the data. Specifically, the route for the GET request should have a string parameter called "query" containing the SPARQL query as a string. The query will be in URL-coded format.
    \item They would prefer if the response was in XML format.
    \item They do not know the size of the data they will be querying nor have an estimation.
\end{enumerate}

At this stage we had gotten enough insight to begin work on the database, however due to the other groups not knowing exactly what they want, there was a possibility of additional tasks emerging later, which would take precedence during the sprint.

From the epics, we created a backlog. As mentioned in section \ref{Whatwelearnedsprint3}, we decided to work with a different unit of measurement for determining the size of a task.
Instead of using hours, we now estimate tasks by relative sizing - but we will keep using the Fibonacci numbers for points.

To approach the prioritization of tasks differently, we decided to apply inversion thinking \cite{InversionThinking}. This involved trying to find issues with our prioitization by imagining what would happen if we did not work on the given tasks. 
We took the items from the backlog that we defined as fulfilling our sprint goal, and tried to think about what would happen if we failed to fulfill them. 
This was done to validate the implementation tasks, as they have the most significant impact on \knox{} as a whole, making sure that they are absolutely necessary. 

\subsection*{Release planning}\label{acceptCriteriaSprint5}
The \textbf{functional requirements} include reading from and writing to the RDF database. 
The read operation should be done through an endpoint which returns the data in the XML format.
Likewise, writing should be facilitated through an endpoint which receives data in the aforementioned Turtle format.


The \textbf{non-functional requirement} for this sprint is simply that the reading and writing operations should be reasonably fast such that an acceptable amount of tuples can be queried within a feasible amount of time.


The \textbf{acceptance criteria} is that the aforementioned functional and non-functional requirements must be met before this feature is deemed acceptable. 


With the planning phase completed, we now have a backlog and a MVP to which we will now begin implementing.